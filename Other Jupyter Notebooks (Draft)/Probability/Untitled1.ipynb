{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920569d5-8437-4884-bbd8-ea1d9205df34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtsa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mar_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoReg, ar_select_order, AutoRegResults\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m norm\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import sys\n",
    "import os\n",
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order, AutoRegResults\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 25})\n",
    "\n",
    "\n",
    "def ramp(x):\n",
    "\n",
    "    if x > 0:\n",
    "\n",
    "        return x\n",
    "\n",
    "    else:\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "\n",
    "            # Parameters\n",
    "            sampling_rate = 100  # samples per second\n",
    "            total_time = 3  # seconds\n",
    "            num_samples = total_time * sampling_rate\n",
    "            time = np.arange(num_samples) / sampling_rate\n",
    "\n",
    "            # Generate sine waves\n",
    "            sine_wave_1 = np.sin(2 * np.pi * 10 * time[:sampling_rate])\n",
    "            sine_wave_2 = np.sin(2 * np.pi * 20 * time[sampling_rate:2 * sampling_rate])\n",
    "            sine_wave_3 = np.sin(2 * np.pi * 30 * time[2 * sampling_rate:])\n",
    "\n",
    "            # Combine the sine waves\n",
    "            signal = np.concatenate([sine_wave_1, sine_wave_2, sine_wave_3])\n",
    "\n",
    "            # Add Gaussian noise\n",
    "            noise = 0.1 * np.random.randn(num_samples)\n",
    "            noisy_signal = signal + noise\n",
    "\n",
    "            # Some initial parameters\n",
    "            for order in [8]: # n of orders in AR model\n",
    "\n",
    "                # Some model parameters...\n",
    "                bn = 4*order # burn in data\n",
    "                e_t = 0.0 # initialising the prediction error\n",
    "                pred_y_t = 0.0 # initialising the predicted state\n",
    "                sigma2_ypred = 0.0\n",
    "                smooth_param = 0.1\n",
    "                state_noise_var = 0.0\n",
    "\n",
    "                # Split data\n",
    "                # train = df_polars_raw_pd_price_last['ret'][:bn].values\n",
    "                # test = df_polars_raw_pd_price_last['ret'][bn:].values\n",
    "                train = noisy_signal[:bn]\n",
    "                test = noisy_signal[bn:]\n",
    "\n",
    "                # Parameters for state noise\n",
    "                # state_noise_t = 0.0 # initialising the state noise (SHOULD BE A MATRIX)\n",
    "                W_t = np.zeros((order, order)) #np.cov(state_noise_t) # initialising the state noise covariance matrix (SHOULD BE A MATRIX)\n",
    "                state_noise_coeff_matrix_tminus1 = np.eye(order) # np.linalg.cholesky(W_t).T # initialising the state noise coefficient matrix (SHOULD BE A MATRIX)\n",
    "                R_tminus1 = np.eye(order)\n",
    "\n",
    "                ## Start the iteration\n",
    "                state_noise_arr = [] # collecting the state noise variance\n",
    "                w_arr = [] # collecting the state noise covariance\n",
    "                e_arr = [] # collecting the prediction error\n",
    "                k_arr = [] # collecting the kalman gain\n",
    "                sigma2_ypred_arr = [] # collecting the estimated prediction variance\n",
    "                q_cov_tminus1_arr = [] # collecting the cov matrix of the predicted state\n",
    "                pred_y_arr = []\n",
    "                pred_q_arr = []\n",
    "                post_arr = []\n",
    "                rho_arr = []\n",
    "                rho_arr_complete = []\n",
    "                sigma2_q0_arr = []\n",
    "\n",
    "                for n, i in enumerate(range(order+1, len(test) + 1)):\n",
    "\n",
    "                    # Compute the vector of observations\n",
    "                    smallerDF_ret = test[i - (order+1):(i)]\n",
    "                    smallerDF_arr = smallerDF_ret[:-1]\n",
    "                    next_data_pt = smallerDF_ret[-1] # t\n",
    "                    F_t = -1 * smallerDF_arr[::-1] # collecting observations from t-1 to t-p\n",
    "\n",
    "                    # print(F_t)\n",
    "\n",
    "                    if n == 0:\n",
    "\n",
    "                        # Obtain the initial estimate for predicted state, their covariance and the observation noise variance\n",
    "                        model_init = AutoReg(train[::-1], trend='n', lags=order).fit()\n",
    "                        pred_q = model_init.params  # initial estimates of state vector\n",
    "                        # sigma2_0 = abs(np.var(F_t))\n",
    "                        #sigma2_0 = np.average([abs(np.var(test[0:10])), abs(np.var(test[int(len(test)/2):int(len(test)/2+10)])), abs(np.var(test[int(len(test)-10):]))])# take in several overlapping blocks of data and compute the variance of the data\n",
    "                        sigma2_0 = 0.2#0.1**2.\n",
    "                        # sigma2_0 = abs(np.var(model_init.resid))\n",
    "                        # sigma2_0 = abs(np.var(train))\n",
    "                        # inv_train = -1 * train[::-1]\n",
    "                        # q_cov_tminus1 = sigma2_0 * np.dot(inv_train, inv_train.transpose())\n",
    "                        ## q_cov_tminus1 = sigma2_0 * np.dot(F_t, F_t.transpose()) # initial state covariance matrix set to the linear regression covariance matrix (p9 penny)\n",
    "                        q_cov_tminus1 = sigma2_0 * np.einsum(\"i,j->ij\", F_t, F_t)\n",
    "                        # q_cov_tminus1 = sigma2_0 * np.einsum(\"i,i\", F_t, F_t) * np.eye(order)\n",
    "                        #print(q_cov_tminus1.shape)\n",
    "\n",
    "                        # Estimate the state noise on-line using Jazwinski algorithm (adaptive kalman filtering); using N (lag/burnin) = 1\n",
    "                        # C = np.einsum(\"i,ij->j\", F_t, q_cov_tminus1)\n",
    "                        # D = np.einsum(\"i,i\", C, F_t)\n",
    "                        # sigma2_q0 = sigma2_0 + D # Compute the estimated predicted variance assuming q=0\n",
    "                        # state_noise_var = ((e_t ** 2) - sigma2_q0) / np.einsum(\"i,i\", F_t, F_t)\n",
    "\n",
    "                    if n > 0:\n",
    "\n",
    "\n",
    "                        # # Estimate the k+1 state noise from k+l where l = 1 on-line using Jazwinski algorithm (adaptive kalman filtering)\n",
    "                        # sigma2_q0 = sigma2_0 + D # Compute the estimated predicted variance assuming q=0\n",
    "                        # new_estimate = ((e_t ** 2) - sigma2_q0) / np.einsum(\"i,i\", F_t, F_t)\n",
    "                        # # state_noise_var = new_estimate\n",
    "                        # state_noise_var = new_estimate #smooth_param * state_noise_var + (1-smooth_param) * new_estimate # updating the state noise variance for next step\n",
    "                        # # print(state_noise_var)\n",
    "                        # state_noise_arr.append(state_noise_var)\n",
    "\n",
    "                        # Compute the predicted observation (mean of the likelihood distribution)\n",
    "                        # we need to / can do this first as we use pred_q from tminus1 to compute pred_y_t\n",
    "                        pred_y_t = np.dot(F_t, pred_q)\n",
    "                        pred_y_arr.append(pred_y_t)\n",
    "\n",
    "                        # Compute the prediction error (e_t)\n",
    "                        e_t = next_data_pt - pred_y_t\n",
    "                        e_arr.append(e_t**2)\n",
    "\n",
    "                        # Updating the observation noise\n",
    "                        # E = np.einsum(\"i,ij->j\", F_t, R_tminus1)\n",
    "                        # F = np.einsum(\"i,i\", E, F_t)\n",
    "                        # sigma2_0 = smooth_param* sigma2_0 + (1-smooth_param) * (e_t**2 - F)\n",
    "\n",
    "                        # Estimate the k+1 state noise from k+l where l = 1 on-line using Jazwinski algorithm (adaptive kalman filtering)\n",
    "                        C = np.einsum(\"i,ij->j\", F_t, q_cov_tminus1)\n",
    "                        D = np.einsum(\"i,i\", C, F_t)\n",
    "                        sigma2_q0 = sigma2_0 + D # Compute the estimated predicted variance assuming q=0\n",
    "                        sigma2_q0_arr.append(sigma2_q0)\n",
    "                        new_estimate = ((e_t ** 2) - sigma2_q0) / np.einsum(\"i,i\", F_t, F_t)\n",
    "                        new_estimate = ramp(new_estimate)\n",
    "                        state_noise_var = smooth_param * state_noise_var + (\n",
    "                                    1 - smooth_param) * new_estimate  # when residuals become large relative to their predicted 1sigma limit, filter is diverging\n",
    "\n",
    "                         # updating the state noise variance for next step\n",
    "                        state_noise_arr.append(state_noise_var)\n",
    "\n",
    "                        # Compute the state noise covariance matrix using state noise variance\n",
    "                        W_t = state_noise_var * np.eye(order)\n",
    "                        w_arr.append(np.linalg.norm(W_t, ord=2))\n",
    "\n",
    "                        # Compute estimated prediction variance (E11)\n",
    "                        R_t = q_cov_tminus1 + W_t\n",
    "                        J = np.einsum(\"i,ij->j\", F_t, R_t)\n",
    "                        sigma_2phi = np.einsum(\"i,i\", J, F_t)\n",
    "                        sigma2_ypred = sigma2_0 + sigma_2phi\n",
    "                        sigma2_ypred_arr.append(sigma2_ypred)\n",
    "\n",
    "                        # Compute the Kalman gain (E10)\n",
    "                        K_t = np.einsum(\"ij,j->i\", R_t, F_t) / sigma2_ypred\n",
    "                        #K_t = np.dot((q_cov_tminus1 + W_t), F_t.transpose()) / sigma2_ypred\n",
    "                        k_arr.append(K_t[0])\n",
    "\n",
    "                        # Compute the learning rate rho\n",
    "                        rho = (1./order) * np.matrix.trace(R_t)\n",
    "                        ## rho_arr.append(rho)\n",
    "                        rho = np.matmul((1/order) * (R_t), F_t.transpose())\n",
    "                        # rho2 = np.matmul(rho, F_t.transpose())\n",
    "                        rho_arr.append(rho.sum())\n",
    "\n",
    "                        rho_c = ((1. / order) * np.trace(R_t))/ sigma2_ypred\n",
    "                        # rho_arr_complete.append(rho_c)\n",
    "                        #rho_c = np.matmul((((1. / order) * (R_t))/ sigma2_ypred), F_t.transpose())\n",
    "                        # rho_c2 = np.matmul(rho_c, F_t.transpose())\n",
    "                        rho_arr_complete.append(rho_c)#.sum())\n",
    "\n",
    "                        # Compute the posterior probability of P(y_t) [EQN 12]\n",
    "                        posterior = norm.pdf(next_data_pt, loc=pred_y_t, scale=np.sqrt(sigma2_ypred)) # computing the posterior probability of seeing y_t\n",
    "                        post_arr.append(posterior)\n",
    "                        #raise SystemExit(0)\n",
    "\n",
    "                        #################################################################################\n",
    "\n",
    "                        ### GETTING READY FOR THE NEXT ITERATION ###\n",
    "                        # Compute the covariance of the state estimate (E9)\n",
    "                        A = np.einsum(\"i,j->ij\", K_t, F_t)\n",
    "                        B = np.einsum(\"ij,jk->ik\", A, R_t)\n",
    "                        q_cov_tminus1 = R_t - B # updating the state covariance matrix for next step\n",
    "                        # print(q_cov_tminus1)\n",
    "                        q_cov_tminus1_arr.append(q_cov_tminus1[0,0])\n",
    "\n",
    "                        # if(state_noise_var==math.inf):\n",
    "                        #     state_noise_var=0.0\n",
    "\n",
    "                        # Update the predicted state (E8)\n",
    "                        pred_q = pred_q + (K_t * e_t) # updating predicted state for the next iteration\n",
    "                        pred_q_arr.append(pred_q[0])\n",
    "\n",
    "                        # R_tminus1 = R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217f6aa-8bdb-4bda-82c5-dc35e9ec0b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
